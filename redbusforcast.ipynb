{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install lightgbm holidays\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import holidays\n",
        "from datetime import timedelta\n",
        "\n",
        "# LOAD your pre-merged lag-enhanced datasets\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test_8gqdJqH.csv\")\n",
        "submission = pd.read_csv(\"sample_submission_TQv3O0x.csv\")\n",
        "\n",
        "# ðŸ§Š Filter for dbd = 15\n",
        "transactions = pd.read_csv(\"transactions.csv\")\n",
        "trans_15 = transactions[transactions['dbd'] == 15]\n",
        "train = pd.merge(train, trans_15, on=['doj', 'srcid', 'destid'], how='inner')\n",
        "test = pd.merge(test, trans_15, on=['doj', 'srcid', 'destid'], how='left')\n",
        "\n",
        "\n",
        "# ---------------------- CALENDAR FEATURES ----------------------\n",
        "def enrich_calendar(df):\n",
        "    df['doj'] = pd.to_datetime(df['doj'])\n",
        "    df['month'] = df['doj'].dt.month\n",
        "    df['dayofweek'] = df['doj'].dt.dayofweek\n",
        "    df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
        "    df['is_month_start'] = df['doj'].dt.is_month_start.astype(int)\n",
        "    df['is_month_end'] = df['doj'].dt.is_month_end.astype(int)\n",
        "    ind_holidays = holidays.India(years=[2023,2024,2025])\n",
        "    df['is_holiday'] = df['doj'].isin(ind_holidays).astype(int)\n",
        "    df['is_pre_holiday'] = df['doj'].apply(lambda x: (x + timedelta(days=1)) in ind_holidays).astype(int)\n",
        "    df['is_post_holiday'] = df['doj'].apply(lambda x: (x - timedelta(days=1)) in ind_holidays).astype(int)\n",
        "    df['is_school_vacation'] = df['month'].isin([5,6,10,11,12]).astype(int)\n",
        "    return df\n",
        "\n",
        "train = enrich_calendar(train)\n",
        "test = enrich_calendar(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNEU3P7prWE0",
        "outputId": "90fcc45a-f17e-4c2b-a2b5-bba624988446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4023419433>:33: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
            "  df['is_holiday'] = df['doj'].isin(ind_holidays).astype(int)\n",
            "<ipython-input-10-4023419433>:33: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
            "  df['is_holiday'] = df['doj'].isin(ind_holidays).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- ENCODE CATEGORICAL ----------------------\n",
        "cat_cols = ['srcid_region', 'destid_region', 'srcid_tier', 'destid_tier']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    train[col] = le.fit_transform(train[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "\n",
        "# ---------------------- FEATURE ENGINEERING ----------------------\n",
        "train['search_per_seat'] = (train['cumsum_searchcount'] + 1) / (train['cumsum_seatcount'] + 1)\n",
        "test['search_per_seat'] = (test['cumsum_searchcount'] + 1) / (test['cumsum_seatcount'] + 1)\n",
        "train['tier_diff'] = abs(train['srcid_tier'] - train['destid_tier'])\n",
        "test['tier_diff'] = abs(test['srcid_tier'] - test['destid_tier'])\n",
        "train['region_match'] = (train['srcid_region'] == train['destid_region']).astype(int)\n",
        "test['region_match'] = (test['srcid_region'] == test['destid_region']).astype(int)\n",
        "\n",
        "# ROUTE STATS\n",
        "route_stats = train.groupby(['srcid', 'destid'])['final_seatcount'].agg(['mean', 'std', 'median']).reset_index()\n",
        "route_stats.columns = ['srcid', 'destid', 'route_mean_seatcount', 'route_std_seatcount', 'route_median_seatcount']\n",
        "train = pd.merge(train, route_stats, on=['srcid', 'destid'], how='left')\n",
        "test = pd.merge(test, route_stats, on=['srcid', 'destid'], how='left')\n",
        "\n",
        "# Lag/Momentum/Volatility Features\n",
        "def create_lag_features(df, group_cols, value_col, lags):\n",
        "    df_lag = df.copy()\n",
        "    for lag in lags:\n",
        "        df_lag[f'{value_col}_lag_{lag}'] = df_lag.groupby(group_cols)[value_col].shift(lag)\n",
        "    return df_lag\n",
        "\n",
        "def create_rolling_features(df, group_cols, value_col, windows):\n",
        "    df_rolling = df.copy()\n",
        "    for window in windows:\n",
        "        df_rolling[f'{value_col}_rolling_mean_{window}'] = df_rolling.groupby(group_cols)[value_col].transform(lambda x: x.rolling(window=window).mean())\n",
        "        df_rolling[f'{value_col}_rolling_std_{window}'] = df_rolling.groupby(group_cols)[value_col].transform(lambda x: x.rolling(window=window).std())\n",
        "    return df_rolling\n",
        "\n",
        "train = create_lag_features(train, ['srcid', 'destid'], 'cumsum_searchcount', [1, 3])\n",
        "train = create_lag_features(train, ['srcid', 'destid'], 'cumsum_seatcount', [1, 3])\n",
        "\n",
        "train['search_growth_1d'] = train['cumsum_searchcount'] - train['cumsum_searchcount_lag_1']\n",
        "train['seat_growth_1d'] = train['cumsum_seatcount'] - train['cumsum_seatcount_lag_1']\n",
        "train['search_growth_3d'] = train['cumsum_searchcount'] - train['cumsum_searchcount_lag_3']\n",
        "train['seat_growth_3d'] = train['cumsum_seatcount'] - train['cumsum_seatcount_lag_3']\n",
        "\n",
        "train = create_rolling_features(train, ['srcid', 'destid'], 'final_seatcount', [7])\n",
        "train['seatcount_volatility'] = train['final_seatcount_rolling_std_7']\n",
        "\n",
        "\n",
        "test = create_lag_features(test, ['srcid', 'destid'], 'cumsum_searchcount', [1, 3])\n",
        "test = create_lag_features(test, ['srcid', 'destid'], 'cumsum_seatcount', [1, 3])\n",
        "\n",
        "test['search_growth_1d'] = test['cumsum_searchcount'] - test['cumsum_searchcount_lag_1']\n",
        "test['seat_growth_1d'] = test['cumsum_seatcount'] - test['cumsum_seatcount_lag_1']\n",
        "test['search_growth_3d'] = test['cumsum_searchcount'] - test['cumsum_searchcount_lag_3']\n",
        "test['seat_growth_3d'] = test['cumsum_seatcount'] - test['cumsum_seatcount_lag_3']\n",
        "\n",
        "\n",
        "\n",
        " #FINAL FEATURE SET\n",
        "features = [\n",
        "    # Original\n",
        "    'srcid', 'destid', 'srcid_region', 'destid_region', 'srcid_tier', 'destid_tier',\n",
        "    'cumsum_seatcount', 'cumsum_searchcount', 'search_per_seat',\n",
        "    'tier_diff', 'region_match',\n",
        "    'month', 'dayofweek', 'is_weekend', 'is_month_start', 'is_month_end',\n",
        "    'is_holiday', 'is_pre_holiday', 'is_post_holiday', 'is_school_vacation',\n",
        "    'route_mean_seatcount', 'route_std_seatcount', 'route_median_seatcount',\n",
        "\n",
        "    # ðŸ”¥ Lag/Momentum/Volatility\n",
        "    'search_growth_1d', 'seat_growth_1d',\n",
        "    'search_growth_3d', 'seat_growth_3d',\n",
        "    'seatcount_volatility'\n",
        "]\n",
        "\n",
        "target = 'final_seatcount'"
      ],
      "metadata": {
        "id": "q2VZFb9i2IzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_for_training = [f for f in features if f != 'seatcount_volatility']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train[features_for_training], train[target], test_size=0.2, random_state=42)\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'learning_rate': 0.02,\n",
        "    'num_leaves': 128,\n",
        "    'max_depth': 12,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.9,\n",
        "    'bagging_freq': 5,\n",
        "    'lambda_l1': 3.0,\n",
        "    'lambda_l2': 6.0,\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_val = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_val],\n",
        "    num_boost_round=3000,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=100)]\n",
        ")\n",
        "\n",
        "# ---------------------- EVALUATE ----------------------\n",
        "val_preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "rmse = mean_squared_error(y_val, val_preds)\n",
        "rmse = np.sqrt(rmse)\n",
        "print(f\"âœ… FINAL VALIDATION RMSE: {rmse:.2f}\")\n",
        "\n",
        "# ---------------------- PREDICT & SUBMIT ----------------------\n",
        "test_preds = model.predict(test[features_for_training], num_iteration=model.best_iteration)\n",
        "submission['final_seatcount'] = np.round(test_preds).astype(int)\n",
        "submission.to_csv(\"final_submission_lag_boosted.csv\", index=False)\n",
        "print(\"ðŸ“¦ Submission saved as: final_submission_lag_boosted.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj3s3WCs2YSx",
        "outputId": "5e023a1c-660c-421e-e1a0-730eb43d24ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2618]\ttraining's rmse: 233.112\tvalid_1's rmse: 376.979\n",
            "âœ… FINAL VALIDATION RMSE: 376.98\n",
            "ðŸ“¦ Submission saved as: final_submission_lag_boosted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CiIUk9Cu9gUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}